'''
æ ¹æ®adapterçš„ä»»åŠ¡åˆ†é…ç­–ç•¥è¿›è¡Œæ¨ç†,è€ƒè™‘æ‰€æœ‰ä»»åŠ¡éƒ½ç”±åŒä¸€ä¸ªæ¨¡å‹åœ¨å•æœºä¸Šæ‰§è¡Œæ¨ç†
'''
# -*- coding: utf-8 -*-
# ä»»åŠ¡åˆ†è§£
import traceback
import os
import json
import os
import sys
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
# è·å–é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.abspath(os.path.join(current_dir, '..', '..'))
# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° sys.path ä¸­
sys.path.append(project_root)
import time
import argparse
from datetime import datetime
from tqdm import tqdm
from paper2.utils.infer_util import *
from paper2.utils.math_util import *
from paper2.utils.decomposition_util import *
from paper2.evaluate import *


# clientå®šä¹‰éœ€è¦æ»¡è¶³å¦‚ä¸‹è°ƒç”¨æ–¹å¼: client.chat.completions.create(model,messages = messages), è¯¦è§askLLMå‡½æ•°
openaiClient = setOpenAi(keyid = 0)
llamaClient = setLocal()
clients = {'gpt': openaiClient, 'llama': llamaClient}
aftername = "after_decomposition_infer"


def parse_args():
    parser = argparse.ArgumentParser(description="Run Task Decomposition for various datasets.")
    
    parser.add_argument(
        '--dataset_name',
        type=str,
        required=True,
        choices=[
            'gpqa', 'math500', 'aime', 'amc', 'livecode', 'nq', 'all_math',
            'triviaqa', 'hotpotqa', '2wiki', 'musique',
            'bamboogle', 'medmcqa', 'pubhealth', 'test'
        ],
        help="Name of the dataset to use (without .json)."
    )

    return parser.parse_args()


def main():
    args = parse_args()
    dataset_name = args.dataset_name
    
    start_time = time.time()
    now = datetime.now()
    formatted_now = now.strftime("%Y-%m-%d-%H-%M-%S")
    # åˆå§‹åŒ–è®°å½•tokenæ¶ˆè€—çš„è·¯å¾„
    tokens_path = f'Tokens/{aftername}/{dataset_name}/token_usage_{formatted_now}.json'  # è®°å½•tokenæ¶ˆè€—çš„æ–‡ä»¶
    # ä½¿ç”¨ os.makedirs() ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»º
    os.makedirs(os.path.dirname(tokens_path), exist_ok=True)
            
    logger, filename = setup_logger(aftername)
    
    with open('../MATH_config.json', 'r') as f:
        config = json.load(f)
    config['tokens_path'] = tokens_path
        
    # è¯»å–åŸå§‹æ•°æ®é›†
    file_path = f'../task_datasets/{dataset_name}/test.json'
    with open(file_path, 'r', encoding='utf-8') as file:
        problems = json.load(file)
        
    # è¯»å–ä¸Šä¸€æ­¥ä»»åŠ¡åˆ†è§£ä¹‹åçš„æ•°æ®é›†
    f = open(f'./results/task_decomposition_result/{dataset_name}/TD_task_decomposition_math500_LLM-Research_Meta-Llama-3-8B-Instruct_2025-08-11-19-38-36.json', 'r')
    content = f.read()
    middleRes = json.loads(content) 

    success_Q = 0
    false_Q = 0
    error_Q = 0
    N = len(middleRes)
    question_ids = list(range(N))
    inferRes = {} # ä¿å­˜æ¨ç†ç»“æœ
    MAX_TRY = 5  # é”™è¯¯å°è¯•ä¸Šé™
    for question_id in tqdm(question_ids):
        
        question = problems[question_id]['Question']
        type = problems[question_id]['subject']
        gold_answer = problems[question_id]['answer']
        
        logger.info('\n\n\n')
        logger.info(f'number id: {question_id}')
        logger.info('problem content:\n')
        logger.info(question)

        attempts = 0
        success = False
        # å…è®¸æ¨¡å‹è¿›è¡Œå¤šæ¬¡æ¨ç†å°è¯•
        while attempts < MAX_TRY and not success:
            try:
                steps, steps_dict, depths, int_edges = middleRes[str(question_id)]['steps'], middleRes[str(question_id)]['steps_dict'], middleRes[str(question_id)]['depths'], middleRes[str(question_id)]['int_edges']
                depths = {int(k): v for k, v in depths.items()}
                heights = list(depths.keys())
                MAXHeight = max(heights)+1
                # print(f"MAXHeight: {MAXHeight}")
                answerDict = {} 
                progress_bar = tqdm(total=len(steps))
                for i in range(MAXHeight):
                    subtasks = depths[i]
                    for subtaskid in subtasks:                
                        number = re.findall(r'\d+', subtaskid)
                        number = int(number[0]) if number else None
                        subtask = steps_dict[str(number)]
                        answer_MODEL = config['subtask_MODEL']
                        # äº¤å¾…è§£å†³ä»»åŠ¡
                        sys_q = f"""There is a math_problem. I need you to solve it and give an answer.
Here is the problem:\n{question} 

I have broken this math problem down into several smaller problems. I will assign you sub-problems one by one, and provide the results of the previous sub-problems as a reference for your reasoning.
Please solve the problem and respond according to mathematical logic.
        """  # ç³»ç»Ÿä»»åŠ¡ä¿¡æ¯
                        
                        if len(answerDict)>0:
                            answersSoFar = f"""\nSo far, the answers to the resolved sub-problems are as follows: The format is Sub-problem-Id: xxx; Sub-problem: xxx; Answer: xxx."""
                            for key, value in answerDict.items():
                                answersSoFar += f"""\nSub-problem-Id: {key}; Sub-problem: {answerDict[key]['subtask']}; Answer: {answerDict[key]['answer']}."""
                            
                            predecessors = search_Predecessors(int_edges, number)
                            intersection = set(answerDict.keys()).intersection(set(predecessors))
                            count = len(intersection)
                            if count>0:
                                answersSoFar += f"""\nAmong them, sub-problems {predecessors} are directly related to this sub-problem, so please pay special attention to them."""
                        
                        
                        subask = f"""\nThe sub-problem to solve now is xxx: {subtask}
Based on the information above, please provide a concise and clear answer"""

                        if len(answerDict)>0:
                            query = answersSoFar+subask
                        else:
                            query = subask

                        Q = [{'role':'system', 'content':sys_q},
                            {'role':'user', 'content':query},]
                        
                        result = askLLM(clients, Q, tokens_path=tokens_path, model=answer_MODEL, temperature=1, max_tokens=300)                        
                        answerDict[number] = {'subtask':subtask, 'answer':result}
                        progress_bar.update(1)

                progress_bar.close()
                # å·²ç»é—®å®Œäº†æ‰€æœ‰çš„subtask,æœ€åé—®ä¸€æ¬¡å¾—åˆ°æœ€ç»ˆçš„ç­”æ¡ˆ
                Q.append({'role':'assistant', 'content':result})
                Q.append({'role':'user', 'content':"""Now that all the sub-problems have been solved, you should provide your final answer in the format \\boxed{YOUR_ANSWER}.
Please give the final answer without any additional explanation or clarification."""})
                # finalResult = askChatGPT(Q, model=GPT_MODEL, temperature=1)
                finalResult = askLLM(clients, Q, tokens_path=tokens_path, model=config['finalSummarize_MODEL'], temperature=1, max_tokens=300)
                # print('å›¾ä¸Šæ¨ç† done')
                logger.info("\n%s", "="*80)
                logger.info("ğŸŸ¢ FINAL RESULT")
                logger.info("%s", finalResult)
                logger.info("%s\n", "="*80)
                  
                inferRes[str(question_id)] = {
                        "question": question,
                        "gold_answer": gold_answer,
                        "infer_answer": finalResult,
                        "subtask_answers": answerDict,
                    }
                success = True
            except (KeyError, ValueError) as e:
                attempts += 1
                tb = traceback.format_exc()
                logger.error(f"[attempt {attempts}] taskid={question_id} ä¸šåŠ¡æ ¡éªŒå¤±è´¥: {e}\n{tb}")
                last_err = e
        
        if attempts == MAX_TRY:
            error_Q += 1
            logger.info(f'run error {MAX_TRY}+')

    # æ„é€ ä¿å­˜è·¯å¾„,å…ˆä¿å­˜æ¨ç†ç»“æœï¼Œä¿å­˜åˆ°results/
    save_dir = f'./results/{aftername}/{dataset_name}'
    os.makedirs(save_dir, exist_ok=True)
    model_name = re.sub(r'[<>:"/\\|?*]', '_', config['decompose_MODEL'])
    infer_save_path = os.path.join(save_dir, f'{aftername}_{formatted_now}_{model_name}.json')
    with open(infer_save_path, 'w', encoding='utf-8') as f:
        json.dump(inferRes, f, indent=2, ensure_ascii=False)
    logger.info(f"Inference results saved to: {infer_save_path}")
    
    # è¿›è¡Œæ•°å€¼è¯„ä¼°/ç»Ÿè®¡F1 em acc math_equal ä¿å­˜åˆ°outputs/
    output_dir = f'./output/{aftername}/{dataset_name}'
    os.makedirs(output_dir, exist_ok=True)
    input_list = [item['question'] for item in inferRes.values()]
    output_list = [item['infer_answer'] for item in inferRes.values()]
    metrics,success_Q, false_Q = run_evaluation(inferRes, input_list, output_list, dataset_name, output_dir=output_dir, total_time=time.time() - start_time,  apply_backoff=False, answer_model=answer_MODEL, aftername=aftername)
    print(metrics)
    
    # è®¡ç®—è¿è¡Œæ—¶é—´
    end_time = time.time()
    elapsed_time = end_time - start_time
    hours, minutes, seconds = seconds_to_hms(elapsed_time)
    logger.info(f"100 solving è¿è¡Œè€—æ—¶: {hours}h, {minutes}min, {seconds}s")
    
    # è®¡ç®—æ‰§è¡Œå‡†ç¡®ç‡
    logger.info(f'\n{tokens_path}')
    logger.info(f'Correct_Q: {success_Q}')
    logger.info(f'False_Q: {false_Q}')
    logger.info(f'Error_Q: {error_Q}\n')
    
    # # è®¡ç®—æ¨ç†tokenæ•°é‡å’Œæ€»æ¨ç†æˆæœ¬cost
    # with open(tokens_path, 'r') as f:
    #     token_usage = json.load(f)
    #     # logger.info(json.dumps(token_usage, indent=4))
    #     total_tokens, total_cost = CountCost(token_usage)
    #     # æ‰“å°ç»“æœ
    #     logger.info(f"Total Tokens: {total_tokens}")
    #     logger.info(f"Total Cost: ${total_cost:.2f}")
            
if __name__ == '__main__':
    main()

    